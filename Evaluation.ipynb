{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGHNr6rDsjwjWdn89SZwJR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nikil263/llm-codechallenge/blob/main/Evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating eval dataset**"
      ],
      "metadata": {
        "id": "6ksMb7bCk8F_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import json\n",
        "\n",
        "# Function to generate random coefficients (including negative ones) and equations\n",
        "def generate_equation():\n",
        "    coefficients = [random.randint(-10, 10) for _ in range(3)]\n",
        "    signs = ['<=', '>=', '=']\n",
        "    sign = random.choice(signs)\n",
        "    return f\"{coefficients[0]}X {'-' if coefficients[1] < 0 else '+'} {abs(coefficients[1])}Y {sign} {coefficients[2]}\"\n",
        "\n",
        "# Function to generate the corresponding Pyomo constraint\n",
        "def generate_constraint(equation):\n",
        "    equation_parts = equation.split()\n",
        "\n",
        "    # Check if equation_parts has enough elements\n",
        "    if len(equation_parts) < 5:\n",
        "        return None\n",
        "\n",
        "    a, sign_b, b = equation_parts[0], equation_parts[1], equation_parts[2]\n",
        "    sign = equation_parts[3]\n",
        "    c = equation_parts[4]\n",
        "\n",
        "    # Format coefficients\n",
        "    a_coeff = f\"{a.strip().replace('X', '')} * model.x\"\n",
        "    b_coeff = f\"{'-' if '-' in sign_b else '+'} {b.strip().replace('Y', '')} * model.y\"\n",
        "\n",
        "    # Combine coefficients, handling the sign of the second coefficient correctly\n",
        "    pyomo_expr = f\"{a_coeff} {b_coeff} {sign} {c.strip()}\"\n",
        "\n",
        "    return f\"model.constraint3 = Constraint(expr={pyomo_expr})\"\n",
        "\n",
        "# Generate the dataset\n",
        "dataset = []\n",
        "for _ in range(100):\n",
        "    equation = generate_equation()\n",
        "    user_input = f\"add a constraint of {equation} in our model.\"\n",
        "    output = generate_constraint(equation)\n",
        "\n",
        "    # Skip if output is None (equation_parts not enough elements)\n",
        "    if output is None:\n",
        "        continue\n",
        "\n",
        "    dataset.append({\"input\": user_input, \"output\": output})\n",
        "\n",
        "# Validate and save the dataset to a JSON file\n",
        "try:\n",
        "    json_data = json.dumps(dataset, indent=4)\n",
        "    with open('eval_dataset.json', 'w') as f:\n",
        "        f.write(json_data)\n",
        "    print(\"Dataset created and saved to 'eval_dataset.json'\")\n",
        "except json.JSONDecodeError as e:\n",
        "    print(f\"JSON error: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"Unexpected error: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mY1Fgl0mUrI6",
        "outputId": "b905f2cb-5d95-43a0-8d8b-1d41133a3653"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset created and saved to 'train.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation**"
      ],
      "metadata": {
        "id": "eWy4gOyBlIL7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtyyCe-AUmm_",
        "outputId": "1ecd885e-cfe3-41c5-988f-6769955cae8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "\n",
        "from transformers import pipeline, GPT2LMHeadModel, GPT2Tokenizer\n",
        "import json\n",
        "\n",
        "# Load the fine-tuned model and tokenizer\n",
        "model_name = \"Nikil263/Fine_Tuned_GPT2model\"\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Initialize the pipeline with the fine-tuned model\n",
        "generator = pipeline('text-generation', model=model, tokenizer=tokenizer)\n",
        "\n",
        "# Load the evaluation dataset\n",
        "with open(\"eval_dataset.json\", \"r\") as f:\n",
        "    eval_data = json.load(f)\n",
        "\n",
        "# Function to generate constraints\n",
        "def generate_constraint(user_input):\n",
        "    response = generator(user_input, max_length=50, num_return_sequences=1)\n",
        "    new_constraint_code = response[0]['generated_text'].strip()\n",
        "    lines = new_constraint_code.split('\\n')\n",
        "    constraint_line = None\n",
        "\n",
        "    for line in lines:\n",
        "      if line.startswith(\"output: model.constraint3\"):\n",
        "        constraint_line = line\n",
        "        break\n",
        "    if constraint_line == None:\n",
        "      return \"\"\n",
        "    constraint_line = constraint_line.replace(\"output: \", \"\")\n",
        "    return constraint_line\n",
        "\n",
        "# Initialize lists to store results\n",
        "y_true = []\n",
        "y_pred = []\n",
        "bleu_scores = []\n",
        "\n",
        "# Smoothing function for BLEU score\n",
        "smooth = SmoothingFunction().method1\n",
        "\n",
        "# Evaluate the model\n",
        "for item in eval_data:\n",
        "    input_text = item['input']\n",
        "    reference_constraint = item['output']\n",
        "\n",
        "    generated_constraint = generate_constraint(input_text)\n",
        "\n",
        "    y_true.append(reference_constraint)\n",
        "    y_pred.append(generated_constraint)\n",
        "\n",
        "    # Calculate BLEU score\n",
        "    reference_tokens = reference_constraint.split()\n",
        "    generated_tokens = generated_constraint.split()\n",
        "    bleu_score = sentence_bleu([reference_tokens], generated_tokens, smoothing_function=smooth)\n",
        "    bleu_scores.append(bleu_score)\n",
        "\n",
        "# Calculate Accuracy\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "\n",
        "# Calculate Average BLEU Score\n",
        "average_bleu_score = sum(bleu_scores) / len(bleu_scores)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(f\"Average BLEU Score: {average_bleu_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otvCm-mfkz0V",
        "outputId": "4b6835c8-0185-40f3-b8bc-861634d57e16"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 72.00%\n",
            "Average BLEU Score: 0.8894\n"
          ]
        }
      ]
    }
  ]
}